# config/trainer.yaml
_target_: pytorch_lightning.Trainer

# —————————————— Distributed & hardware ——————————————
accelerator: gpu              # or "cpu"
devices: auto                 # can be a list [0,1] or "auto"
strategy: auto                # ddp, ddp_spawn, etc., or "auto"
num_nodes: 1

# —————————————— Precision & performance ——————————————
precision: 16                 # mixed‐precision training (use 32 / 16 / bf16 / amp)
benchmark: true               # torch.backends.cudnn.benchmark
deterministic: false
inference_mode: true

# —————————————— Logging & checkpointing ——————————————
logger: true                  # use default TensorBoardLogger if available
enable_checkpointing: true
enable_progress_bar: true
enable_model_summary: true

# —————————————— Callbacks ——————————————
callbacks: null

# —————————————— Training schedule ——————————————
max_epochs: 100               # stop after N epochs; set to -1 for infinite
min_epochs: null              # force at least N epochs, or omit
max_steps: -1                 # stop after this many optimizer steps
min_steps: null

max_time: null                # "1:00:00" or {hours:1}
fast_dev_run: false

# —————————————— Validation & testing ——————————————
limit_train_batches: 1.0      # float fraction or int num batches
limit_val_batches: 1.0
limit_test_batches: 1.0
overfit_batches: 0.0

val_check_interval: 1.0       # every epoch (1.0), or fraction, or int num batches
check_val_every_n_epoch: 1
num_sanity_val_steps: 2

# —————————————— Logging frequency ——————————————
log_every_n_steps: 50

# —————————————— Gradient & optimizer behavior ——————————————
accumulate_grad_batches: 1
gradient_clip_val: null       # e.g. 1.0
gradient_clip_algorithm: norm

# —————————————— Dataloader behavior ——————————————
use_distributed_sampler: true
reload_dataloaders_every_n_epochs: 0

# —————————————— Profiling & debugging ——————————————
profiler: null                # "simple", "advanced", or a path to your own
detect_anomaly: false
barebones: false

# —————————————— Other misc ——————————————
plugins: null
sync_batchnorm: false
default_root_dir: ./outputs   # override via CLI or env
model_registry: null

